# 后端技术栈梳理与改进建议（大厂后端实习向）

## 一、当前后端技术栈（准确表述）

可以这样区分：**框架与基础设施** / **数据与存储** / **AI 与外部服务** / **部署**。

| 类别 | 技术 | 说明 |
|------|------|------|
| **语言与框架** | Java 17、Spring Boot 3.2 | 主运行时与 Web 框架 |
| **Web 与接口** | Spring Web（REST）、Spring WebFlux（WebClient） | 同步 API + 异步 HTTP 客户端调 Piston |
| **持久化** | Spring Data JPA、H2（文件模式） | 面经、题库、简历、投递、会话等落库 |
| **AI 与 RAG** | LangChain4j、智谱 GLM | RAG = Embedding + 向量检索 + 拼 prompt 调 LLM；当前无 Tool/Function Calling |
| **其他依赖** | PDFBox、Jackson | PDF 解析、JSON 序列化 |
| **部署与运维** | Docker（Piston）、Nginx、阿里云 ECS | 单 jar 部署；Piston 用 Docker 自建 |

**需要澄清的两点**：
- **RAG** 是「检索增强生成」的架构/能力，不是单独一个技术栈；实现上 = LangChain4j 的 Embedding + EmbeddingStore + 检索 + 拼进 Prompt 调大模型。
- **Docker** 在你项目里主要用于跑 Piston，主应用是单 jar 直接跑在 ECS 上，所以简历上写「Docker 自建 Piston」比泛写「Docker」更准确。

**一句话总结当前后端技术栈**：  
Java 17 + Spring Boot 3.2（Web + JPA + WebFlux）+ LangChain4j（RAG + 多模型调用）+ H2 + 智谱 GLM + Docker（Piston）+ 阿里云 ECS。

---

## 二、面试时「够不够」、可能被问到的点

- **已经能讲、且对实习够用的点**：  
  Spring Boot、JPA、REST、WebClient 调外部 API、RAG 流程（embedding → 存/查向量 → 拼 prompt）、@Async、Filter 鉴权、单 jar 部署、Docker 自建 Piston 的动机与步骤。

- **容易显得「偏薄」或追问会深的点**：  
  - 数据库：只用 H2，没有 MySQL/PostgreSQL，索引、事务、连接池等问不深。  
  - 缓存：没有 Redis，缓存、限流、会话一致性等不好展开。  
  - AI 应用形态：目前是「RAG + 固定 prompt 调模型」，没有 **Agent / 工具调用（Function Calling）**，大厂很多业务在做「模型选动作、后端执行」这类能力，面试官可能会问有没有做过。

所以：**现有技术栈对「有项目经验、能讲清楚」已经够用**；若想**增加可讲深度和差异化**，优先建议加 **Function Calling（Tool Use）**，其次再考虑 Redis、换 MySQL、以及可选的 MCP。

---

## 三、改进建议（按优先级）

### 1. 优先做：Function Calling / Tool Use（强烈推荐）

**是什么**：让大模型在对话中「决定要调用哪些后端能力」，并返回结构化参数，由你后端执行（查面经、查题库、跑代码等），再把结果塞回对话。这样就从「纯 RAG + 单次调用」升级成「带工具调用的 Agent」，技术点和可讲点都多很多。

**在项目里可以怎么做**：
- 用 **LangChain4j 的 @Tool** 定义若干工具方法，例如：
  - `searchInterviews(company, department)`：按公司/部门查面经，返回摘要或条数。
  - `getAlgorithmQuestion(questionId)`：根据 ID 取一道算法题（题面、默认代码等）。
  - `runCode(language, code)`：调用现有 CodeExecutionService 跑代码，返回执行结果摘要（或「运行成功/失败」）。
- 把这些 Tool 注册到 **AiServices** 里，和 ChatLanguageModel 一起组成一个「面试助手 Agent」：用户可以说「帮我查一下字节后端的面经」「给我一道 LRU 缓存题」「用 Java 跑一下这段代码」，模型决定调哪个 tool、传什么参数，你后端执行后把结果返回给模型，模型再生成自然语言回复。

**面试可讲点**：  
Tool 的语义设计、参数 schema 如何给模型、如何解析模型返回的 tool call、执行失败时的重试或降级、和现有 RAG 的配合（例如先 RAG 再决定是否查库/跑代码）。

**实现参考**：  
- LangChain4j 官方： [Tools (Function Calling) | LangChain4j](https://docs.langchain4j.dev/tutorials/tools/)  
- 在现有 `InterviewChatService` 或新建 `InterviewAgentWithToolsService` 中，用 `AiServices.builder(...).tools(yourToolObjects).build()` 把 RAG + 对话 + Tool 串起来。

---

### 2. 建议做：Redis（缓存 / 限流 / 会话）

**做什么**：
- **RAG 检索结果缓存**：相同 company+department+query 短时间内的检索结果可缓存 5～10 分钟，减轻 embedding 与向量检索压力。  
- **接口限流**：对 `/api/execute` 或智谱调用按 IP 或用户限流，防止刷接口。  
- （可选）**会话/对话缓存**：把当前轮次的上下文 key 存 Redis，便于多实例时会话一致（你目前单机可先不做）。

**面试可讲点**：  
缓存 key 设计、过期策略、缓存穿透/击穿怎么避免（简单版即可）、限流算法（固定窗口/滑动窗口/令牌桶）。

**技术**：  
Spring Data Redis 或 Spring Boot Starter Data Redis，本地可 Docker 起一个 Redis。

---

### 3. 可选：MySQL / PostgreSQL 替代或并存 H2

**做什么**：  
增加对 MySQL 或 PostgreSQL 的支持（通过 profile 或配置切换），把 JPA 的实体和 Repository 复用在真实关系库上。

**面试可讲点**：  
索引设计（如 company、department 联合查询）、事务隔离级别、连接池（HikariCP）配置、和 H2 的差异（文件库 vs 独立数据库）。

**优先级**：  
比 Function Calling 和 Redis 低一档；若时间紧可只准备「为什么用 H2、生产会考虑换成 MySQL」的说法即可。

---

### 4. 可选：MCP（Model Context Protocol）

**是什么**：  
MCP 是一种「让 LLM 使用外部工具/数据源」的协议，服务端暴露工具列表和调用方式，客户端（或你的后端）按协议调用。和你自己做的 Function Calling 有重叠：都是「模型选工具、后端执行」。

**和当前项目的关系**：
- **自己项目里**：用 LangChain4j 的 Tool 就足够，不必先上 MCP；大厂面试更常问的是「你有没有做过工具调用 / Agent」，而不是「你有没有接 MCP 服务」。
- **若想体现「协议与扩展性」**：可以后续把现有能力（如 searchInterviews、getAlgorithmQuestion）封装成 MCP Server 暴露出去，让其他前端或 Agent 按 MCP 调用；这样简历上可以写「支持通过 MCP 暴露面经检索、题库等能力」。

**结论**：  
先做 **Function Calling**，把「模型 + 工具」跑通并讲清楚；MCP 作为「可选扩展」放在后面，有时间再加。

---

### 5. 其他可加分项（时间允许再做）

- **可观测性**：  
  接入 Micrometer + Prometheus（或仅打指标）、或结构化日志（JSON + traceId），便于讲「线上问题如何排查」。
- **健壮性**：  
  对 Piston、智谱等外部调用做超时、重试（如 resilience4j 或简单重试），避免单点超时拖死接口。
- **安全**：  
  管理员接口除密码外，可加简单限流或 IP 白名单；若后面做多用户，再考虑 JWT/Session。

---

## 四、改进后技术栈与简历表述建议

**若完成 Function Calling + Redis**，技术栈可以写成类似：

- **后端**：Java 17、Spring Boot 3.2、Spring Data JPA、Spring WebFlux、**LangChain4j（RAG + Tool/Function Calling）**、智谱 GLM、**Redis**、H2、Docker、阿里云 ECS  

简历项目描述里可加一句：  
「在 AI 面试对话中引入 **Function Calling**：模型可根据用户意图调用后端工具（面经检索、题库查询、代码执行等），由服务端执行后把结果返回模型再生成回复，实现简单 Agent 闭环。」

**面试可讲点会明显增多**：  
RAG 流程、Tool 设计、参数校验、与 RAG 的配合、Redis 缓存/限流、部署与排错。这些对「互联网大厂后端 Java 实习」已经比较够用。

---

## 五、Function Calling 已实现说明

项目中已实现 **Function Calling（Tool Use）**：

- **后端**  
  - `InterviewAssistantTools`：使用 LangChain4j `@Tool` 定义 4 个工具  
    - `searchInterviews(query, company, department)`：按公司/部门/关键词检索面经  
    - `listAlgorithmQuestions(difficulty)`：列出题库算法题（可选难度）  
    - `getAlgorithmQuestionById(questionId)`：根据 ID 获取题目详情  
    - `runCode(language, code)`：调用 Piston 执行代码并返回结果摘要  
  - `InterviewAgentWithToolsService`：用 `AiServices.builder().chatLanguageModel().tools(tools).build()` 组装带工具的助手，根据用户消息自动选工具并回复。  
  - 接口：`POST /api/interviews/chat-with-tools`，body `{ "message": "用户输入" }`，返回 `{ "reply": "助手回复" }`。

- **前端**  
  - 「AI 面试模拟」页新增 **「智能助手（Function Calling）」** 区域：输入框可输入如「查一下字节后端的面经」「给我一道中等难度的算法题」等，助手会调用相应工具后生成自然语言回复。  
  - 助手回复中的 URL（力扣链接、本站在线 IDE 链接）会渲染为可点击链接；访问 `/#/ide?questionId=题目ID` 可在在线 IDE 中直接打开对应题目。
- **按题名查题与双链接**  
  - 新增工具 `findAlgorithmQuestionByTitle(题名)`：用户说「我要搜索插入位置」「给我反转链表」时会按标题在题库中查找，返回正确题目。  
  - 题目详情中返回「力扣/原题链接」与「本站在线IDE做题链接」；后者需在配置中设置 `app.base-url`（如 `http://8.138.47.162:8080`）才会生成。

面试时可说：在对话中接入了 LangChain4j 的 Tool，定义了面经检索、题库查询、代码执行等工具，模型根据用户意图选择调用并汇总结果回复，实现简单 Agent 闭环。

---

## 六、总结

| 问题 | 简要回答 |
|----------|----------|
| 主要后端技术栈是什么？ | Java 17、Spring Boot 3.2、JPA、WebFlux、LangChain4j（RAG）、H2、智谱 GLM；部署上有 Docker（Piston）、Nginx、阿里云 ECS。RAG 是架构能力，用 LangChain4j 实现。 |
| 是不是可问的点不够？ | 对实习来说当前能讲的点已经够用；想再加深，最值得加的是「模型 + 工具调用」和「缓存/限流」。 |
| 需要怎么改进？ | **优先**：在对话中接入 **Function Calling（LangChain4j @Tool）**，让模型能调面经检索、题库、代码执行等。**建议**：加 **Redis** 做 RAG 缓存或接口限流。**可选**：MySQL、MCP、可观测性、重试与限流。 |
| 要不要用 MCP、Function Calling？ | **Function Calling 强烈建议做**，是面试和项目深度的重要加分项。**MCP 可选**，可在 Tool 能力稳定后再考虑把能力通过 MCP 暴露。 |

