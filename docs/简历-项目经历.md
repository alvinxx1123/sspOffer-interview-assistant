# 简历项目经历：sspOffer 面经助手（互联网大厂后端 Java 实习向）

---

## 一、面向「后端 Java 开发实习」的简历项目经历（推荐直接使用）

**sspOffer 面经助手 — 互联网面试准备平台（含 Function Calling）**  
**项目时间**：20xx.x — 20xx.x（请按实际填写）  
**技术栈**：Java 17、Spring Boot 3.2、Spring Data JPA、Spring WebFlux、LangChain4j、H2、Docker、Nginx、阿里云 ECS  

**项目描述**：  
基于 RAG 与大模型的面经整合与 AI 面试准备 Web 应用，支持面经检索、AI 面试模拟、面试复盘、在线算法 IDE、简历与投递管理，并通过 Function Calling 让大模型可自动调用「查面经、查题库、跑代码」等后端能力；前后端分离，单 jar 部署，已上线阿里云。

**负责内容（后端为主）**：
- **RAG 与 AI 面试模拟**：使用 LangChain4j 实现面经向量化（EmbeddingModel + InMemoryEmbeddingStore）与相似度检索，检索结果拼入 System Prompt 后调用智谱 GLM 生成深挖问题；面经批量入库时用 `@Async` 异步建索引，避免上传接口超时
- **Function Calling 智能助手**：基于 LangChain4j 定义 Tool（查面经、查算法题、按 ID 获取题目、运行代码等），实现 `InterviewAgentWithToolsService`，根据用户意图自动选择调用相应 Tool，并在「算法题」场景下绕过大模型自由生成，由后端直接返回标准 Markdown 回复
- **算法题题库与在线 IDE**：设计 `AlgorithmQuestion` 等实体，使用 Spring Data JPA + H2 存储题库；提供 `list/find/getById` 接口支撑 Function Calling，结合本地题库与在线 IDE 实现「随机抽题」「按标题查题」「通过 questionId 跳转到 IDE」等能力
- **联网搜索算法题原题链接**：封装 `AlgorithmProblemSearchService` 调用 SearchCans/Bing/Serper 等 API，构造 `site:leetcode.cn/problems/ 题目名` 等查询，并在解析结果时同时校验「URL 为题目页」与「标题包含题目名」，只在命中时返回力扣原题链接，未命中则返回「未搜索到原题」提示，避免把「不同路径」错配为 3Sum 等错误题目
- **代码执行服务**：基于 Spring WebFlux 的 WebClient 调用 Piston 执行 API，设置超时与默认 URL 兜底；对 Java 源码做入口识别（有无 `static void main`），无 main 时注入测试类、有 main 时做类顺序归一化，保证 Piston 以正确入口执行
- **部署与线上问题**：前后端打单 jar 部署阿里云 ECS；公网 Piston 超时导致运行失败，改为 Docker 自建 Piston，通过环境变量注入 `PISTON_API_URL`，配合 Nginx 反向代理与超时配置，解决线上「Host is not specified」「Failed to fetch」等问题，并编写部署与排错文档
- **其他后端模块**：管理员密码鉴权（Filter 校验 `X-Admin-Password` 请求头）、面经/简历/投递的 CRUD 与 JPA 持久化、多模态接口解析面经图片/PDF 用于复盘

**项目亮点**：  
- 从需求分析、后端设计、前端对接到阿里云部署均由本人独立完成，具备从开发到线上排错的完整闭环实践  
- 在 RAG、代码执行之外，补全了「Function Calling + 算法题」链路，完整打通「本地题库 → 联网搜题 → 在线 IDE」的闭环  
- 针对大模型输出 HTML 导致链接乱码、点击跳空白页的问题，设计「后端零 HTML + URL 强清洗 + 前端 cleanHref + 旧 HTML 保护」的多层防线，最终实现只输出一条可点击的纯净链接  
- 针对联网搜题错配问题，引入「URL 为题目页 + 标题包含题目名」的双重约束，宁缺毋滥，避免把错题当原题返回，提高了系统可信度与可解释性

---

## 二、精简版（3～4 条 bullet，版面紧时用）

**sspOffer 面经助手** | Java 17、Spring Boot 3.2、JPA、WebFlux、LangChain4j（Function Calling）、Docker、阿里云 ECS  

- 基于 **LangChain4j** 实现面经 **RAG** 与 Function Calling：向量化存储 + 相似度检索支撑 AI 出题，同时将「查面经、查算法题、运行代码」封装为 Tool 供大模型按需调用
- 设计**算法题题库 + 在线 IDE**：支持随机抽题、按标题查题、本地题库优先；本地无题时调用 SearchCans/Bing/Serper 联网搜力扣原题，并通过「URL 为题目页 + 标题包含题名」双约束、URL 强清洗与前端 cleanHref 确保只输出一条可点击的纯净链接
- 负责**代码执行服务**：WebFlux WebClient 调用 Piston API，超时与 URL 兜底；Java 源码入口识别与类顺序处理，保证多类/无 main 场景可执行
- **部署与排错**：单 jar 部署阿里云 ECS；公网 Piston 超时，改为 **Docker 自建 Piston**，配合环境变量 + Nginx 配置解决线上运行失败；实现管理员鉴权（Filter）、面经/简历/投递 CRUD 与 JPA 持久化、多模态解析用于复盘；项目已上线

---

## 三、可能被问到的面试题与回答思路

以下按「项目深挖」和「技术原理」分类，便于准备大厂后端 Java 实习面试。

---

### （一）项目整体与你的角色

**1. 简单介绍一下这个项目，你负责哪些部分？**

**回答要点**：  
项目是面向互联网求职的面试准备平台，核心是面经检索 + AI 出题 + 在线写算法。我负责后端整体设计与实现：RAG 面经检索与 AI 面试模拟、在线 IDE 依赖的代码执行服务、管理员鉴权、面经/简历/投递的 CRUD，以及部署到阿里云和线上代码执行超时后的 Docker 自建 Piston 方案与文档。

**2. 为什么做这个项目？技术选型怎么考虑的？**

**回答要点**：  
自己找实习时需要整理面经和练算法，希望有一个能按公司/部门查面经、并能根据简历和面经自动出题的练习环境。技术选型上：后端用 Spring Boot 3 + JPA 快速落地 CRUD 和持久化；RAG 用 LangChain4j 做向量检索和 LLM 调用，减少自己写 prompt 与 embedding 的细节；代码执行用开源 Piston 避免自建沙箱；部署用单 jar + 阿里云 ECS，方便一台机跑前后端和自建 Piston。

---

### （二）RAG 与 AI 相关

**3. RAG 在你项目里是怎么实现的？流程说一下。**

**回答要点**：  
面经先落库（JPA 存 H2），同时把「公司、部门、岗位、内容」等拼成一段可检索文本，用 LangChain4j 的 EmbeddingModel（如 AllMiniLM）转成向量，存入 EmbeddingStore（我用的 InMemoryEmbeddingStore）。检索时：用户选公司/部门或输入问题，先对 query 做 embedding，再用 embeddingStore.findRelevant 做相似度检索，取 topK 条面经文本，拼进大模型的 System/User Prompt，让智谱 GLM 根据这些面经和用户简历生成深挖问题。  
（若问向量存哪：当前是内存存储，重启会丢，所以启动时从 DB 全量扫面经再异步重建索引。）

**4. 为什么用 InMemoryEmbeddingStore？有什么优缺点？生产会怎么改进？**

**回答要点**：  
项目是个人/小规模使用，数据量不大，用内存实现简单、无额外依赖，检索也快。缺点是重启后向量丢失，所以我在启动时用 CommandLineRunner 从数据库拉全量面经，再通过 @Async 异步调用 RAG 的 index 方法重建索引。  
生产上会考虑用持久化向量库，例如 Redis 存向量、或专门的向量数据库（如 Milvus、pgvector），并做增量索引而不是每次全量重建。

**5. 面经批量上传时为什么要用 @Async 做异步索引？**

**回答要点**：  
批量上传时如果同步做 embedding 和写入向量库，请求会拖很久，容易 502 或超时。所以保存面经到 DB 后，只触发一次异步方法，在后台线程里对这批数据做向量化和索引，接口立刻返回，用户体验更好。同时要处理好异步里的异常，避免静默失败，我们打了日志并在失败时做监控告警（可简单说「有日志与后续可加告警」）。

---

### （三）代码执行与 WebClient

**6. 在线 IDE 的代码执行是怎么做的？为什么用 WebFlux 的 WebClient？**

**回答要点**：  
后端不自己跑用户代码，而是把代码和语言等信息通过 HTTP 发给外部的 Piston 服务（开源代码执行 API）。流程是：前端发 POST 到我们后端的 /api/execute，后端用 WebClient 再 POST 到 Piston 的 /execute，拿到 stdout/stderr/exitCode 后封装返回给前端。  
用 WebFlux 的 WebClient 是因为它是非阻塞的，适合调用外部 HTTP 服务；我们这里用 block 是因为当前接口是同步语义，但底层仍可用 Reactor 的超时、重试等能力，例如 block(Duration.ofSeconds(30)) 避免一直等 Piston。

**7. Java 代码有多类或没有 main 方法时，你怎么处理的？**

**回答要点**：  
Piston 执行 Java 时以「第一个类」为入口，所以要把带 main 的类放到最前面。我这边先用正则检测代码里有没有 `static void main`（不要求一定是 public）：如果没有，就自动生成一个 Main 类，里面 main 里 new Solution() 并调用常见题的方法（如 twoSum）；如果有，就找到包含 main 的类，把该类在源码里的顺序挪到最前面（保留 import 等），再发给 Piston，这样入口就对了。

**8. 线上为什么会出现「Host is not specified」「Failed to fetch」？你怎么解决的？**

**回答要点**：  
「Host is not specified」说明请求 Piston 时用的 URL 是空的或未配置，多半是环境变量 PISTON_API_URL 没在服务器上生效（例如没写进 env 文件或没重启服务）。  
「Failed to fetch」是浏览器端的报错，一般是前端等后端响应超时：当时后端去调公网 Piston（emkc.org）从国内访问很慢或超时，后端一直 block 等结果，导致前端请求超时。  
解决方式是：在同一台 ECS 上用 Docker 自建 Piston，把 PISTON_API_URL 配成 http://127.0.0.1:2000/api/v2，这样后端只访问本机，延迟低；同时 Nginx 的 proxy_read_timeout 设大一点（如 60s 以上），避免代理先超时。并写了文档记录部署步骤和这些报错的排查方法。

---

### （四）Spring、JPA、Filter

**9. 管理员密码校验是怎么做的？为什么用 Filter？**

**回答要点**：  
对写操作（POST/PUT/DELETE/PATCH）要求请求头里带 X-Admin-Password，且与配置里的 app.admin-password 一致，否则返回 403。实现上用一个继承 OncePerRequestFilter 的 Filter，Order 设成 1 优先执行；只对 /api 开头的路径做校验，OPTIONS 预检直接放行并带上 CORS 头；若未配置密码则放行（方便本地开发）。用 Filter 是为了在进入 Controller 之前统一做鉴权，所有写接口都生效，避免在每个接口里重复判断。

**10. 你们用 JPA 存面经和题库，有没有考虑过分页？**

**回答要点**：  
面经列表、部门列表等查询用了 JPA 的 Repository，按公司、部门查。当前数据量不大，没有做分页；若数据量上来，会用 Pageable 做分页，例如 `findByCompany(company, Pageable)`，避免一次查全表。H2 文件库持久化，重启数据不丢。

**11. Spring Boot 3 和 2 在你项目里用到了哪些区别？**

**回答要点**：  
主要用的是 Jakarta 命名空间（javax 改为 jakarta），例如 jakarta.servlet、jakarta.persistence；以及最低 JDK 17。依赖里用 spring-boot-starter-web、data-jpa、webflux 等，没有特别用到 3 独有的新 API，但整体在 3.x 上跑没问题。

---

### （五）部署与运维

**12. 单 jar 是怎么打的？前端怎么一起打包？**

**回答要点**：  
前端用 npm run build 打出 dist，Maven 的 resources 插件在 prepare-package 阶段把 frontend/dist 拷到 target/classes/static，再打成一个 Spring Boot fat jar，所以一个 jar 里既有后端又带前端静态资源，部署时只传这一个 jar 到服务器即可。

**13. Docker 自建 Piston 时遇到过什么坑？**

**回答要点**：  
一是 Piston 官方镜像要求挂载的 /piston 目录不能是空目录，且仓库里的 packages 是源码目录不是运行时目录，直接挂载会报 ENOTDIR；解决是克隆仓库后删掉 packages 再建空 packages 目录再挂载。二是要在容器里用 ppman 安装 Java/Python 等语言，否则执行会报 runtime unknown。三是部署后要在服务器上配环境变量 PISTON_API_URL 并重启应用，否则后端仍连不到自建 Piston。这些都在项目文档里写了。

---

### （六）综合与扩展

**14. 如果让你优化这个项目，你会做哪些？**

**回答要点**：  
（可按优先级说）① RAG 向量持久化，用 Redis 或向量库 + 增量索引；② 代码执行加队列或限流，防止恶意刷运行占满 Piston；③ 管理员鉴权改为 JWT 或 Session，支持多用户/角色；④ 面经、题库接口加分页与缓存；⑤ 加监控与日志（如 Piston 调用失败率、接口耗时），便于线上排错。

**15. 项目中遇到的最大难点是什么？怎么解决的？**

**回答要点**：  
可以说「线上代码执行一直失败」：本地正常，部署后要么 Host is not specified 要么 Failed to fetch。先查日志和环境变量，确认是 Piston 地址未生效 + 公网 Piston 从国内访问超时。然后查资料决定自建 Piston，用 Docker 部署、按文档处理 packages 目录和语言安装，再配环境变量和 Nginx，并写文档把步骤和常见错误记下来，之后类似问题都能按文档排查。体现定位问题、查资料、做方案、落地并沉淀文档的过程。

